{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training and Evaluation (Training Loop)\n",
        "### This code trains the model using training data and evaluates its accuracy on the validation test."
      ],
      "metadata": {
        "id": "H1PlpUWz758c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Training Loop"
      ],
      "metadata": {
        "id": "fg6gnzVn7vlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import time\n",
        "import torch\n",
        "\n",
        "# Define path del mejor modelo en Drive\n",
        "BEST_MODEL_PATH = os.path.join(PROJECT_PATH, 'best_simple_model.pth')\n",
        "\n",
        "def train_model(model, criterion, optimizer, num_epochs=10):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    history = {'val_acc': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "        model.train()\n",
        "        for inputs, labels in dataloaders['train']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        running_corrects = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dataloaders['val']:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes['val']\n",
        "        history['val_acc'].append(epoch_acc.item())\n",
        "        print(f'Validation Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "            print(f\">>> New best model saved at: {BEST_MODEL_PATH}\")\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    print(f\"\\nBest Validation Accuracy: {best_acc:.4f}\")\n",
        "    return model\n",
        "# Execute training\n",
        "model_ft = train_model(model_ft, criterion, optimizer, num_epochs=10)\n",
        "# Verify model saved\n",
        "time.sleep(2)\n",
        "if os.path.exists(BEST_MODEL_PATH):\n",
        "    file_size = os.path.getsize(BEST_MODEL_PATH) / (1024*1024)\n",
        "    print(\"Model checkpoint saved in Drive\")\n",
        "    print(f\"Location: {BEST_MODEL_PATH}\")\n",
        "    print(f\"Size: {file_size:.2f} MB\")\n",
        "else:\n",
        "    print(\"ERROR: Model was NOT saved in Drive.\")"
      ],
      "metadata": {
        "id": "pdshnwdt13Nr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}